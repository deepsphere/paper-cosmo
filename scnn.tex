%%
%% Copyright 2007, 2008, 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references
%% SP 2008/03/01

% \documentclass[preprint,12pt,authoryear]{elsarticle}
\documentclass[final,twocolumn,3p,times,authoryear]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times,authoryear]{elsarticle}
%% \documentclass[final,1p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,3p,times,authoryear]{elsarticle}
%% \documentclass[final,3p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,5p,times,authoryear]{elsarticle}
%% \documentclass[final,5p,times,twocolumn,authoryear]{elsarticle}


%\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}


%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
\usepackage{color}
\usepackage{url}
% \usepackage{hyperref}
\usepackage[draft]{hyperref}
\usepackage{graphicx,array} \graphicspath{{figures/}}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{bm}
\usepackage{aasmacros}

\usepackage{enumitem} % to remove when done with todo list

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\newcommand{\nati}[1]{{\color[rgb]{.1,.6,.1}{#1}}}
\newcommand{\TK}[1]{{\color{red}{TK:#1}}}
\newcommand{\todo}[1]{{\color[rgb]{.6,.1,.6}{#1}}}
\newcommand{\assign}[1]{{\color[rgb]{.8,.5,.8}{Assigned: #1 }}}

\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\tabref}[1]{Table~\ref{tab:#1}}
\newcommand{\secref}[1]{Section~\ref{sec:#1}}
%\newcommand{\secref}[1]{\S\ref{sec:#1}}
\newcommand{\eqnref}[1]{(\ref{eqn:#1})}

\renewcommand{\b}[1]{{\bm{#1}}}   % bold symbol

% MATH SYMBOLS
\newcommand{\1}{\b{1}}              % all-ones vector
\newcommand{\0}{\b{0}}              % all-zero vector
\newcommand{\g}[1]{\b{#1}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\V}{\mathcal{V}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\B}{\mathcal{B}}
\renewcommand{\L}{\b{L}}
\newcommand{\tL}{\tilde{\L}}
\newcommand{\W}{\b{W}}
\newcommand{\I}{\b{I}}
\newcommand{\D}{\b{D}}
\newcommand{\U}{\b{U}}
\newcommand{\x}{\b{x}}
\newcommand{\X}{\b{X}}
\newcommand{\y}{\b{y}}
\newcommand{\Y}{\b{Y}}
\newcommand{\bu}{\b{u}}
\newcommand{\f}{\b{f}}
\newcommand{\trans}{^\intercal}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bLambda}{\b{\Lambda}}
\newcommand{\blambda}{\b{\lambda}}
\newcommand{\bO}{\mathcal{O}}
\newcommand{\T}{\mathcal{T}}
\DeclareMathOperator*{\esp}{E}
\DeclareMathOperator*{\var}{Var}
\DeclareMathOperator*{\vect}{vec}
\DeclareMathOperator*{\argmin}{arg \, min}
\newcommand{\pkg}[1]{\texttt{#1}}


\journal{Astronomy and Computing}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\title{HealpixNet: Efficient spherical Convolutional Neural Network with HEALPix sampling for cosmological applications}
% \title{Efficient Spherical ConvNet with Graph Convolutions for Cosmological Applications}
% \title{HealpixNet: Efficient spherical Convolutional Neural Network with graphs and HEALPix sampling for cosmological applications}
%\title{HealpixNet: Graph Convolutional Neural Network for efficient spherical convolutions on HEALPix sampling for cosmological applications}
% Graph Convolutional Networks for efficient spherical ???
% Efficient spherical ??? with GCNs and HEALPix sampling
% (Tomek) How about HealpixCNN? Or HealpixNet? Or HealNet?}
% spherical convolutions with graphs

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \address[label1]{}
%% \address[label2]{}

\author[SDSC]{Nathanaël Perraudin}
\author[EPFL]{Michaël Defferrard}
\author[ETHZ]{Tomasz Kacprzak}

\address[SDSC]{Swiss Data Science Center (SDSC), Zurich, Switzerland}
\address[EPFL]{Institute of Electrical Engineering, EPFL, Lausanne, Switzerland}
\address[ETHZ]{Institute for Particle Physics and Astrophysics, ETHZ, Zurich, Switzerland}

\begin{abstract}

%Convolutional Neural Networks (CNNs) are becoming an important analysis tool in cosmology and astrophysics.
% Michaël: useful info? To me this is not an argument for our approach. Maybe we have to expand it?

% Architectures are then designed similarly to the classical CNNs used for image analysis.
% HealpixCNN (???) uses Tensorflow as the underlying engine and can utilize most of it functionalities.
% Michaël: not relevant for the abstract in my opinion

Convolutional Neural Networks (CNNs) are now a cornerstone of the Deep Learning toolbox and have led to many breakthroughs in Artificial Intelligence.
So far, these networks have mostly been developed for regular Euclidean domains such as those supporting images, audio, or video.
Because of their success, CNN-based methods are becoming increasingly popular in Cosmology.
Cosmological data often comes in a form of spherical maps, which makes the use of traditional CNNs more complicated.
The commonly used pixelzation scheme for spherical maps is HEALPix, which uses an equal-area, isolatitude sampling.
We present a spherical CNN for analysis of full and partial HEALPix maps, which we call HealpixNet.
We construct a spherical CNNs by representing the sphere as a graph.
Graphs are versatile data structures which can represent pairwise relationships between objects or act as a discrete representation of a continuous manifold.
Using the graph-based representation, we define many of the standard CNN operations, such as convolution and pooling, with filters restricted to being radial.
This way, HealpixNet is a special case of a graph CNN, tailored to the HEALPix sampling of the sphere.
% TBD if we include it
% This approach is very efficient computationally than using spherical harmonics to perform convolutions, an alternative that has been explored previously.
An advantage of this representation is that the convolution operations with this approach are very efficient, which enables the algorithm to run very fast.
We demonstrate the method on a classification problem of mass maps from two cosmological models and compare the performance of the CNN with that of two baseline classifiers, based on the power spectrum and pixel density histogram.
Our experimental result shows that the performance of HealpixNet to always be better or equal to both of these baselines.
For high noise levels and for data covering only a smaller fraction of the sphere, HealpixNet achieves typically 10\% better classification accuracy than those baselines.
Finally, we propose a visualization of filters learned by the HealpixNet from the mass maps as some analysis tool for the neural network.
Code and examples are available at \todo{\url{https://github.com/SwissDataScienceCenter/HealpixNet}}.

%As a response to that fact, we are witnessing an increasing interest in the generalization of CNNs to graphs.
% Graphs are versatile data structures which can represent pairwise relationships between objects or act as a discrete representation of a continuous manifold.
% In this paper we take the latter view and represent a sampled sphere as a graph, for which we define the convolution and pooling operations.
% Spherical maps appear in many applications, such as the study of phenomena on the Earth for meteorologists or on the sky for cosmologists.
% A popular format for spherical maps is HEALPix, which uses an equal-area, isolatitude sampling.
% Hence, we present a spherical CNN for analysis of full and partial HEALPix maps, which we call HealpixNet.
% \nati{I am not that we should talk about pooling in the abstract. Another angle would be to say that HEALPix sampling is well suited for spherical CNN with graphs as a) it is very regular => the graph capture well the spherical structure of the Manifold and b) pooling is natural.}
% While the convolution on arbitrary graphs has mostly been sorted out, a general pooling operation has not been discovered so far.
% As such, while HealpixNet is a special case of a graph CNN, it is tailored to the HEALPix sampling of the sphere.
% This approach is computationally much more efficient than using spherical harmonics to perform convolutions, an alternative that has been explored previously.
% The filters learned by the HealpixNet are restricted to being radial.
% Michaël: not necessary in the abstract?
% We demonstrate the method on a classification problem of mass maps from two cosmological models.
% \nati{Should we specify what are the baselines? I think not.}
% A standard benchmark for that problem is to train an SVM on the histograms of map pixel values. Another is to use the power spectral density instead.
% HealpixNet achieves \todo{xx\%} better accuracy than those baselines, is more robust to noise, and is \todo{faster?}.
% Code and examples are available at \todo{\url{https://github.com/xxx}}.
\end{abstract}

\begin{keyword}
Spherical Convolutional Neural Network \sep
HealpixNet \sep
Graph CNN \sep
Cosmological data analysis \sep
Mass mapping
\end{keyword}

\end{frontmatter}

%% \linenumbers

\section*{TODO list}
\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
    \item (TK) check text figure 1
	\item (TK) Related work in cosmo. The only cosmological applications of spherical CNNs in the related work are about projection on the tangent plane \citep{schmelze2017cosmologicalmodel, fluri2018deep, gupta2018nongaussianinformation}. Aren't there applications in cosmology for the other (c.f. related work section) approaches? Most of them are illustrated in omnidirectional imagery. If none, say it and mention some alternatives, e.g., wavelets?
	\item (MD) distinction between CNN and FCN
	\item (MD) check paragraph on our chosen architecture in the Experiments sections
    \item (MD) check vertex interpretation in Efficient convolutions. Powers of L are weights of paths.
    \item (TK) check if papers which appear as arxiv were not published in a conference or journal
    \item (TK) check part sphere notebook and whole sphere
    \item (TK) read everything
    \item (NP) Put Raphael in the dataset author. 
    \item (done!) (TK) add small description of maps\_downsampled\_64.npz in the whole\_sphere notebook. \nati{We need to talk about that.}
	\item (TK) Example applications for dense prediction (classification and regression) for cosmology (color text in 2.8)
	\item (Probably OK) Beware to not confuse reader with synonyms, e.g. pixelization and sampling.
	\item (Should be done) Check names: we use HealpixNet, HealpixNet (CNN variant), HealpixNet (FCN variant)
    \item (I think it is OK) (NP) Check the wording. Be sure that the convolution on SO(3) is clear: we want to say (a) is the one associated with the SO(3) rotation group (b) can be performed  in the spectral domain by a multiplication (c) is equivariant to rotation (d) is described well in Section 2 of \citep{kondor2018clebsch}.
	\item (Done) (NP) Change equation after (2) and check all kroneker
	\item (Everyone should check this) Notation: write element $i$ of vector $y$ as $y_i$, $y(i)$, or $y[i]$? Be consistent. Same for matrices. Keep indices.
	\item (TK) Font: do we have to use times (set in the documentclass)? I (MD) find the rendering of math a bit ugly.
    \item (TK) fix the bibliography
    \item Check links in footnotes.

\end{itemize}

\begin{figure*}
	\centering
    % \includegraphics[width=\linewidth]{architecture}
	\includegraphics[width=\linewidth]{figure_architecture_v3.pdf}
	\caption{Overall network architecture, showing here two convolutional layers acting as feature extractors followed by a fully connected layer with softmax acting as the classifier.
    %\nati{add the stat layer?}
    %\TK{added stats layer to figure text, hope that's OK}
    A convolutional layer is based on five operations: convolution, non-linearity, batch normalization, down-sampling, and pooling. While most operations are agnostic to the data domain, the convolution and the down-sampling have to be adapted. In this paper, we propose first to model the sphere with a graph and to perform the convolution on the graph. Graphs are versatile data structures which can model any sampling, even irregular or partial. Second, we propose to exploit a hierarchical pixelization of the sphere for the pooling operation. It allows the network to analyze the data at multiple scales while preserving the spatial localization of features. This figure shows a network which operates on the whole sphere. The process is, however, the same when working with parts of sphere, except that the graph is only built for the part of interest.}
	\label{fig:architecture}
\end{figure*}

\section{Introduction}
\label{sec:intro}

%\subsection{Motivation}

Cosmological and astrophysical data often come in the form of spherical sky maps.
Observables that cover large parts of the sky, such as the Cosmic Microwave Background (CMB) \citep{planck2015cosmologicalparameters,komatsu2011sevenyear,staggs2018recentdiscoveries}, neutral hydrogen \citep{santos2015cosmologySKA,HI4PI2016fullskyHI}, galaxy clustering \citep{alam2017clusteringgalaxies}, gravitational lensing \citep{troxel2017darkenergy,hildebrandt2017kidscosmological}, and others, have been used to constrain cosmological and astrophysical models.
Cosmological information contained in these maps is usually extracted using summary statistics, such as the power spectra or higher order correlation functions.
Convolutional Neural Networks (CNN) have been proposed as an alternative analysis tool in cosmology thanks to its ability to automatically design relevant statistics to maximise the precision of the parameter estimation
\citep{schmelze2017cosmologicalmodel,luciesmith2018machinelearning,gupta2018nongaussianinformation,gillet2018deeplearning,hassan2018reionizationmodels,aragoncalvo2018classyfyinglarge,ciuca2017cnnstring,ravanbakhsh2017estimating}.
This is possible as CNNs have the capacity to build very rich models and capture complicated, non-linear patterns, which are often present in the data.

% \TK{I would move the discussion about this to a later place in the paper}
% Convolutional Neural Networks (CNNs) are particularly well suited for analysis of cosmological data due to the translation invariance built into their architecture.
% Indeed, sky maps are rotation invariant, which means that rotating maps on the sphere doesn't change their interpretation.
% Only the statistics of the maps is relevant.
% The location of the map on the sky is always fixed (by where the telescope was looking), and most of the models tested are homogeneous and isotropic (the cosmological principle).
% As such, learned weights can be shared across the sphere: the network does not have to relearn to detect objects or features at every spatial location.

% \todo{@Tomek: can you explain why we care about parts of the sphere? (that is an advantage of the graph model over the spherical harmonics)}
% \todo{@Tomek: How is the data acquired? Do telescopes and satellites take measurements according to the HEALPix sampling? (it is also an advantage of our method to be agnostic to the sampling, which might be useful to researchers working with missing data or different models)}
% \nati{@Tomek: I think what Michael has in mind is that the graph approach is very versatile and extendable. It can be used with other samplings (even irregular ones) or only part of the sphere. This flexibility might be an advantage to mention. In particular, compared to~\citet{cohen2018sphericalcnn} it allows us to do only do the required computation when only a part of the sphere is considered.}

So far these algorithms have mostly been demonstrated on Euclidean domains, such as flat images.
Perhaps the most straightforward approach to the analysis of spherical data is to divide it into small chunks and project those on flat 2D surfaces. 
% \todo{Tune according to the story in the related work.}
While this approach has been demonstrated to work \citep{fluri2018deep,gupta2018nongaussianinformation,schmelze2017cosmologicalmodel,gillet2018deeplearning}, it may be more natural for some applications and accurate to work directly on the sphere.
The main challenge in designing a CNN on the sphere is to define a convolution operation that is suitable for this domain, while taking care of the necessary irregular sampling.
Furthermore, to be able to train the network efficiently, the convolution has to be performed fast.
Another important feature is for a CNN to be able to work on subpart of the sphere, as for many cosmological observations cover only a part of the sky.
For ground-based observations this can be due to limited visibility of the sky from a particular telescope location, and for space-based instruments due to masking of the galactic plane area (see for example \figref{example_maps}). 

% cohen2017convolutional (ICML workshop) and cohen2018sphericalcnn (ICLR best paper) are redundant
A first direction to generalize CNNs to spherical data was to apply a standard 2D CNN to a grid discretisation of the sphere~\citep{boomsma2017spherical,su2017sphericalconv,coors2018spherenet}. While this approach uses the well-developed 2D convolution and hierarchical pooling, it is restricted to those specific grid samplings which are highly irregular on the sphere and hence inherently deform the domain where the data is supported. 
A second direction attempted by~\citet{cohen2018sphericalcnn} was to leverage the spherical Fourier transform and to perform the convolution associated to the SO(3) rotation group in the spectral domain, thanks to the convolution theorem.
Contrarily to the first direction, the resulting convolution is rotational equivariant, meaning that a rotation of the input implies the same rotation of the output.
This is an important property as translation invariance is probably one of the main reasons why classic CNNs are successful in the first place.
Nevertheless, this approach is computationally expensive even if a fast spherical Fourier transforms is used. 
%(They exist for particular samplings.)
Finally, the use of a graph to model the discretised sphere was considered by~\citet{khasanova2017graphomni} as well, towards the goal of designing a  network that is invariant to rotations.
While their architecture accommodates these invariances on the sphere and remains fairly efficient, they did not take advantage of a hierarchical pixelisation and use as pixelisation a grid discretisation of the sphere. 
Moreover, the statistical layer, which introduces the invariance, needs to be hand-crafted to capture statistics of interest.

%\todo{better identify the shortcomings: (i) part of sphere / missing data, (ii) computational efficiency, (iii) equivarience}
\nati{The part of the sphere/missing data is not really there, but I still do not know how to include it!}

To overcome those shortcomings, we introduce an efficient spherical CNN formulation which uses (i) convolutions on graphs and (ii) hierarchical pooling, while working with the HEALPix sampling.
The main idea is to represent the sphere $S^2$, a 2-dimensional manifold embedded in $\mathbb{R}^3$, as a graph of connected pixels.
The length (or weight) of the shortest path between two pixels is an approximation of the geodesic distance between them on the manifold.
The use of this approach is enabled by recent developments in graph signal processing, where fundamental tools, such as for example the Fourier transform, were defined for graphs \citep{shuman2013emerging}.
Our approach uses the graph CNN formulation introduced by \citet{defferrard2016convolutional}, which can accommodate any sampling of the sphere.
Using a $k$-nearest neighbours graph, the convolution operation costs $\mathcal{O}(N_{pix})$ operations, where $N_{pix}$ is the number of pixels.
This is the lowest possible complexity for a convolution operation without approximations (e.g., by sketching).
The flexibility of modeling the data domain with a graph allows to easily model data that spans only a part of the sphere, or data that is not uniformly sampled.
Our hierarchical pooling strategy exploits a hierarchical pixelisation of the manifold to analyse the data at multiple scales.
% Such hierarchical pixelisations of the sphere have been well studied.

In this work we present and release HealpixNet\footnote{\url{https://github.com/SwissDataScienceCenter/HealpixNet}}, an algorithm and software package which implements an efficient CNN on HEALPix maps. It is implemented with \pkg{TensorFlow} \citep{abadi2016tensorflow} and is intended to be easy to use out-of-the-box for cosmological applications.
HealpixNet is readily apt to solve four tasks: (i) global classification (i.e., predict a class from a map), (ii) global regression (i.e., predict a set of parameters from a map), (iii) dense classification (i.e., predict a class for each pixel of a map), and (iv) dense regression, (i.e., predict a set of maps from a map).
As HEALPix~\citep{gorski2005healpix} is the most popular sampling used in cosmology and astrophysics, we tailored our method to that particular sampling.
The elements of the graph that depend on the sampling are:
(i) the choice of neighboring pixels when building the graph, and
(ii) the choice of parent pixels when building the hierarchy of layers.
% It is also possible to use multiple HEALPix maps within our framework and use datasets in form of ``shells''.
% These shells can span the radial direction, so that a tomographic analysis can be performed, or different frequencies, in case of data from observations in radio frequencies.
% \nati{I do not know about that last point. Yes we can do it. But a) we did not do it and b) the filter will be spherical in all directions includeding the radial one... I am not sure this is a disirable features.}
% \todo{I think you got it wrong there. I guess the idea is that each shell would be a feature map, i.e., the graph signal would be multi-dimensional.}
% \TK{OK, let's talk about it.}
%\nati{I am not sure this goes there...} Other recently developed sampling methods include \citep{mcewen2011novelsampling}, where exact sampling theorem for equiangular MW sampling was presented.

We give a practical demonstration of the application of our package to cosmological model discrimination using convergence maps, similar to the ones used by \citet{schmelze2017cosmologicalmodel}.
In a simplified scenario, we classify convergence maps on parts of a sphere into two cosmological models.
These models were designed to have the same power spectrum in range $\ell < 1000$.
We compare the performance of our spherical CNN to a baseline algorithm, an SVM classifier which takes pixel histograms or power spectrum densities (PSDs) of these maps as input.
The comparison is made as a function of the additive noise level and the used area of the sphere. Results show that our model is better at discriminating the maps and is more resilient to noise.

The paper is organized as follows.
In \secref{related}, we describe existing approaches to convolutions on spheres, graphs, and manifolds.
\secref{method} exposes the construction of a graph given the HEALPix sampling of a sphere and defines the convolution operation.
Finally, \secref{experiments} presents our experimental results on the weak lensing mass map classification problem. There we compare our method to two standard benchmarks and show its superiority.
%We conclude in \secref{conclusion}.

% Cite the following papers:
% \begin{itemize}
%     \item HEALPix paper \citep{gorski2005healpix}
%     \item First DES mass maps \citep{chang2017curvedsky}
%     \item HEALPix convolutions with asymetric beams \citep{mitra2011fastpixel}
%     \item Mass mapping on the sphere \citep{wallis2017mappingdark}
%     \item Wavelets on the sphere \citep{leistedt2016wavelet} and ball \citep{leistedt2012exactwavelets}
%     \item Planck main result \citep{planck2015cosmologicalparameters,komatsu2011sevenyear}
%     \item HI map \citep{HI4PI2016fullskyHI,}
%     \item more radio maps from Adam+Hamsa \citep{santos2015cosmologySKA}
%     \item more astro science on the sphere, what other survey make maps?
%     \item alternative sampling on the sphere \citep{mcewen2011novelsampling} MW sampling
%     \item cite kids tomographic power spectrum \citep{koehlinger2017kidstomographic}
% \end{itemize}


% \subsection{Potential applications}
% 	\assign{Tomek, Nathanaël, Michaël}

% The analysis of spherical cosmological data, such as the cosmic microwave background \cite{...}, as done in \cite{he2018analysis}, is the target application of our method.

% While our method was developed with cosmology in mind, it can easily target any problem where data live on a sphere. Examples include, but are certainly not limited to, (i) efficient compression and decompression of \ang{360} videos (see \cite{su2017learning}), (ii) \todo{data analysis on planets? (climate, forecasting, temperature, wind)}, (iii) \todo{particle physics? (jets on detectors, but they are usually cylindrical)}, (iv) \todo{applications in Cohen's papers?}.

% Finally, not that those neural networks are not restricted to the sphere and can be applied to any problem where we have data on a graph, such as social, biological or infrastructure networks [some citations, e.g. brain Alzeihmer, particle physics, computer graphics].
% the convolution is not restricted to the sphere, the coarsening/pooling is


\section{Method}
\label{sec:method}
% \begin{itemize}
% 	\item We build a graph using the healpix sampling
% 	\item Define Fourier transform and show that the harmonics are visually close to the spherical harmonics
% 	\item Define spherical convolution using the graph Fourier transform and show heat diffusion example
% 	\item Show the limits of the approach and explain why we cannot have a perfect spherical convolution with this technique
% \end{itemize}

\begin{figure*}
\includegraphics[width=\linewidth]{figures/figure_example_maps.pdf}
\caption{Exmaple maps on the sphere:
(left) the CMB temperature (K) map from Planck \citep{planck2015overview}, with galactic plane masked,
(middle) map of galaxy number counts (number of galaxies per arcmin$^2$) in SDSS DR14 \citep{abolfathi2017sdssDR14},
and (right) simulated weak lensing convergence map (dimensionless) simulated with DES DR1 mask \citep{des2018dr1}.
These maps were pixelised using \texttt{nside}=512.
The CMB and weak lensing mass maps were smoothed with Gaussian kernels with FWHM=1 deg, and the galaxy count map with FWHM=0.5 deg.
}
\label{fig:example_maps}
\end{figure*}

A CNN is composed of the following main building blocks~\citep{lecun1998cnn}:
(i) a convolution,
(ii) a non-linearity,
(iii) a down-sampling operation,
(iv) a pooling operation, and
(v), optionally,  normalization.\footnote{\citet{ioffe2015batchnorm} have shown that batch normalization helps training. We verified this experimentally in our setting as well.}
Our architecture is depicted in~\figref{architecture} and discussed in greater details in \secref{architecture}. As operations (ii) and (v) are point-wise, they do not depend on the data domain. The pooling operation is simply a permutation invariant aggregation function which does not need to be adapted either. The convolution and down-sampling operations, however, need to be generalized from Euclidean domains to the sphere.

On regular Euclidean domains, such as 1-dimensional time series or 2-dimensional images, a convolution can be efficiently implemented by sliding a localized convolution kernel (for example a patch of 5x5 pixels) in the signal domain.
Likewise, down-sampling can be achieved by taking one pixel out of $n$.
Because of the irregular sampling, there is no straightforward way to define a convolution on the sphere directly in the pixel domain; convolutions are most often performed using spherical harmonics.
In our method we also use the spectral domain to define the convolution.
The implementation, however, does not need a direct access to the spectrum, which is computationally more efficient (see \secref{efficient_convolution}).
% We will therefore use the spectral domain to define the convolutions
% \footnote{Note that we only use the spectrum to define the convolution.
% The implementation however does not need a direct access to the spectrum, which is computationally much more efficient. See \secref{efficient_convolution}.}
% \TK{moving footnote to the main text }
The gist of our method is to define the convolution operation on a sphere using a graph, and the down-sampling operation using a hierarchical pixelisation of the sphere.


\subsection{HEALPix sampling}
\label{sec:healpix}


% \begin{figure}
%     \centering
%     \begin{subfigure}[b]{0.45\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{exampleEarthTopo}
%         \caption{}
%         \label{fig:example_earth}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.45\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{exampleCMB}
%         \caption{}
%         \label{fig:example_cmb}
%     \end{subfigure}
%     \caption[]{Example of (a) an Earth topography map composed of \textasciitilde 3 million pixels (\textasciitilde 7 arcmin resolution) and (b) a model of the Cosmic Microwave Background (CMB) radiation temperature anisotropy, composed of \textasciitilde 13 million pixels (\textasciitilde 3.4 arcmin resolution).\footnotemark}
%     \label{fig:example_maps}
% \end{figure}

Before doing any numerical analysis on the sphere, one first has to choose a tessellation, i.e., an exhaustive partition of the sphere into finite area elements, where the data under study is quantized.
The simplicity of the spherical form belies the intricacy of global analysis on the sphere.
There is no known point set which achieves the analogue of uniform sampling in Euclidean space and allows exact and invertible discrete spherical harmonic decompositions of arbitrary but band-limited functions.
Any existing proposition of practical schemes for the discrete treatment of such functions on the sphere introduces some systematic error dependent on the global properties of the point set.
While our method is applicable to any pixelisation of the sphere, two details depend on the chosen sampling: (i) the choice of neighbours in the construction of the graph, and (ii) the choice of parent nodes when coarsening the graph.
As HEALPix~\citep{gorski2005healpix} is the most popular sampling used in cosmology, our target application, we'll tailor the method to that particular sampling in the subsequent exposition.
%We'll note in later sections where the method should be adapted for a different sampling.

HEALPix is a particular case of a more general class of schemes which are based on a hierarchical subdivision of a base polyhedron.
%Many discretized maps of the sphere are based on a hierarchical subdivision of a base polyhedron.
Another example is the geodesic grids which are based on geodesic polyhedrons, i.e., polyhedrons made of triangular faces. A counter-example is the equirectangular projection, which is not constructed from a base polyhedron, although it can be subdivided.
In the particular HEALPix case, the base is a rhombic dodecahedron, i.e., a polyhedron made from 12 congruent rhombic faces.\footnote{A rhombus is a quadrilateral whose four sides all have the same length.}
See \figref{pooling} for an illustration of the base rhombic dodecahedron and its subdivisions.

HEALPix is an acronym for Hierarchical Equal Area isoLatitude Pixelization of a sphere.
This pixelisation produces a hierarchical subdivision of a spherical surface where each pixel covers the same surface area as every other pixel.
A hierarchy is desired for the data locality in the computer memory.
Equal area is advantageous because white noise generated by the signal receiver gets integrated exactly into white noise in the pixel space.
Isolatitude is essential for the implementation of a fast spherical transform.
HEALPix is the sole pixelisation scheme which satisfies those three properties.

The lowest possible resolution is given by the base partitioning of the surface into $N_{pix} = 12$ equal-sized pixels (right-most sphere in \figref{pooling}).
As each pixel is subdivided in four, the second coarser resolution is $N_{pix} = N_{side}^2 \cdot 12 = 2^2 \cdot 12 = 48$ pixels (middle sphere in \figref{pooling}), the third is $N_{pix} = N_{side}^2 \cdot 12 = 4^2 \cdot 12 = 192$ pixels, etc., where $N_{side} = 1, 2, 4, 8, \ldots$ is the grid resolution parameter.
High-resolutions HEALPix maps easily reach millions of pixels.
\figref{example_maps} shows two examples of HEALPix maps: the Cosmic Microwave Background \citep{planck2015overview}, galaxies found in Sloan Digital Sky Survey Data Release 14 \citep{abolfathi2017sdssDR14}, and an example simulated mass map on the footprint of Dark Energy Survey Data Release 1 \citep{des2018dr1}.

\subsection{Graph construction}

Our graph is constructed as an approximation of the continuous 2D manifold that is the surface of the sphere.
Indeed, \citet{belkin2007convergence} showed that the graph Laplacian converges to the Laplace-Beltrami when the number of pixels goes to infinity.
While our construction will not exactly respect the setting defined by \citet{belkin2007convergence}, we observe empirically strong evidence of convergence.

From the HEALPix pixelization, we build a weighted undirected graph $\G = (\V, \E, \W)$, where $\V$ is the set of $N_{pix} = |\V|$ nodes, $\E$ is the set of edges, and $\W$ is the weighted adjacency matrix.
In our graph, each pixel $i$ is represented by a node (also called vertex) $v_i \in \V$.
Each node $v_i$ is then connected to the $8$ (or $7$)\footnote{\label{neighbors}The $12 \cdot 4 = 48$ pixels at the corner of each rhombus of the base dodecahedron only have 7 neighboring pixels. See Figures~\ref{fig:healpix_graph_4} and~\ref{fig:pooling}.} nodes $v_j$ which represent the neighboring pixels $j$ of pixel $i$, forming edges $(v_i, v_j) \in \E$. Given those edges, we define the weighted adjacency matrix $\W \in \R^{N_{pix} \times N_{pix}}$ as
\begin{equation*}
	\W_{ij} = \begin{cases}
		\exp \left( -\frac{\|\x_i-\x_j\|_2^2}{\rho^2} \right) & \text{if pixels $i$ and $j$ are neighbors,} \\
		0 & \text{otherwise,} \\
	\end{cases}
\end{equation*}
where $\x_i$ is a vector encoding the 3-dimensional coordinates of pixel $i$, and
\begin{equation*}
	\rho = \frac{1}{|\E|} \sum_{(v_i, v_j) \in \E} \|\x_i-\x_j\|_2
\end{equation*}
is the average Euclidean distance over all connected pixels. This weighting scheme is important as distances between pixels are not equal.
Other weighting schemes are possible. For example,~\cite{khasanova2017graphomni} uses the inverse of the distance instead. We found out that the one proposed above works well for our purpose, and did not investigate other approaches, leaving it to future work.
\figref{healpix_graph_4} shows a graph constructed from the HEALPix sampling of a sphere.

% mdeff: Why not $1/d$? See Pascal's paper
% nati: The question is: is $1/d$ also good when we have 7/8 neighbors instead of 4? Practically, we can also use $1/d$, but that means changing the code and re-runing the experiment. We probably do not have to change any parameter though... @mdeff: do you think we should try this for this paper? Or we keep that for the next one.
% mdeff: I tried and the eigenvectors and eigenvalues are mostly the same. To me, there is no point in trying for trying. We should rather come up with a definition of distance that will make the eigenvectors closer to the real spherical harmonics.
% Agreed: I added a reference to Pascal paper.

\subsection{Graph Fourier basis}

Following~\cite{shuman2013emerging}, the normalized graph Laplacian,
defined as $\L = \I - \D^{-1/2} \W \D^{-1/2}$, is a second order differential operator
that can be used to define a Fourier basis on the graph. Here $\D$ is the diagonal
matrix where $\D_{ii} = \b{d}_i$ and $\b{d}_i = \sum_j \W_{ij}$ is the weighted degree of node $v_i$. By construction, the Laplacian is symmetric positive
semi-definite and hence can be decomposed as $\L = \U \bLambda \U\trans$, where $\U = [\b u_1, \ldots, \b u_{N_{pix}}]$ is an
orthonormal matrix of eigenvectors and $\bLambda$ is a diagonal matrix of
eigenvalues. The graph Fourier basis is defined as the Laplacian eigenvectors, motivated by the fact that a Fourier basis should diagonalize the Laplacian operator.
The graph Fourier transform of a signal $\f \in \R^{N_{pix}}$ is simply its projection on the eigenvectors given by
$\hat{\f} = \mathcal{F}_\G \{\f\} = \U\trans \f$. It follows that the inverse graph Fourier transform reads $\mathcal{F}^{-1}_\G \{\hat{\f}\} = \U\hat{\f} = \U \U\trans \f = \f$.
Note that the Fourier modes are ordered in the increasing order of the Laplacian eigenvalues $\bLambda$, which can be interpreted as squared frequencies.
Indeed,
\begin{equation*}
	\bLambda_{ii} = \b u_i\trans \L \b u_i = \sum_{(v_j, v_k) \in \E} \frac{\W_{jk}}{\sqrt{\b d_j \b d_k}} (\U_{ji} - \U_{ki})^2
\end{equation*}
is a measure of the variation of the eigenvector $\b u_i$ is on the graph defined by the Laplacian $\L$.


Figure \figref{graph_harmonics} shows the Fourier modes of a HEALPix graph, created using the graph construction described above.
The graph Fourier modes resemble the spherical harmonics.
That is a strong hint that the graph is able to capture the spherical properties of the HEALPix sampling.
This topic is further discussed in \ref{sec:comparison_spherical_harmonics}.

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{eigenvectors}
	\caption{The first 16 eigenvectors of the graph Laplacian, an equivalent of Fourier modes, of a graph constructed from the HEALPix sampling of the sphere.
    Eigenvectors 1--3 could be associated with spherical harmonics of degree $\ell=1$ and order $|m|=(0,1)$, eigenvectors 4--8 with degree $\ell=2$ and order $|m|=(0,1,2)$, and eigenvectors 9--15 with degree $\ell=3$ and order $|m|=(0,1,2,3)$.
    Nevertheless, the graph eigenvectors are only approximating spherical harmonics.}
	\label{fig:graph_harmonics}
\end{figure}

\subsection{Convolution on graphs}
\label{sec:graph_convolution}


As there is no notion of translation on a graph, we cannot convolve two graph signals in a strict sense.
We can, however, convolve a signal with a kernel defined in the spectral domain.
More precisely, we can filter a graph signal by a kernel.
Given the convolution kernel
$h: \R_+ \rightarrow \R$, a signal $\f \in \R^{N_{pix}}$ on the graph is filtered as
\begin{equation} \label{eqn:graph_convolution_fourier}
	h(\L) \f = \U h(\bLambda) \U\trans \f,
\end{equation}
where $h(\bLambda)$ is a diagonal matrix where $h(\bLambda)_{ii} = h(\bLambda_{ii})$, and $h(\bLambda) \hat{\f}$ is the spectral representation of $\f$ after filtering.

Contrary to classical signal processing on Euclidean domains, the kernel $h$ has no single representation in the vertex domain and cannot be translated on the graph. It can however be \textit{localized} on any vertex $v_i$ by the convolution with a Kronecker delta\footnote{A Kronecker delta is the signal $\b \delta^i \in \R^{N_{pix}}$ that is zero everywhere except on vertex $v_i$ where it takes the value one.} $\b \delta^i \in \R^{N_{pix}}$. The localization operator $\T_i$ reads $\T_i h = h(\L) \b \delta^i = (h(\L))_i$, the $i$th column of $h(\L)$.
This localization of the kernel $h$ can be useful to visualize kernels, as explained in~\ref{sec:filter_visualization}.
If the graph is not regular, i.e., all nodes do not have the same number of neighbors, and all distances are not equal, the effect of the kernel will slightly differ from one node to another. While there is no perfect sampling of the sphere, these differences are negligible as the structure of the whole graph is very regular. However, when considering only parts of the sphere, one can observe important border effects (see \figref{border_effects} and~\ref{sec:border_effects}).

Finally, the graph convolution can be interpreted in the vertex domain as a scalar product with localizations $\T_i h$ of the kernel $h$. Indeed, the result of the convolution of the signal $\f$ with the kernel $h$ is
\begin{equation} \label{eqn:graph_convolution_spatial}
	(h(\L) \f)_i = \langle \T_i h(\L), \f \rangle = \langle h(\L) \b \delta^i, \f \rangle.
\end{equation}
To make the parallel with the classical 1D convolution, let $f, g\in \mathbb{Z} \rightarrow \mathbb{R}$ be two 1D discrete signals. Their convolution can be written in the same form as \eqnref{graph_convolution_spatial}:
\begin{equation*}
	(f \ast g) [i] = \sum_{j=-\infty}^\infty f[j] g[i-j] = \langle T_i g,  f \rangle,
\end{equation*}
where $T_i g[j] = g[i-j]$ is, up to a flip, a translation operator. 
% nati: I think now the indexing is clear and will not confuse with the rest of the paper.
Similarly as \eqnref{graph_convolution_spatial}, the convolution of the signal $f$ by a kernel $g$ is the scalar product of $f$ with translated versions $T_i g$ of the kernel $g$.
% Signals and kernels are the same thing in classical signal processing precisely because there exists a proper definition of translation.
% For Michael: I know what you mean here, but it is slightly more complicated than that. 
Additionally, it turns out that the localization operator $\T_i h$ is a generalization of the translation operator on graphs. In the particular case where the Laplacian matrix $\L$ is circulant, $\T_i h$ is a translated version of $\T_j h$ for all $i, j$ and both convolutions are equivalent. We refer the reader to \citet[Sec 2.2]{perraudin2017stationary} for a detailed discussion of the connection between translation $T_i$ and localization $\T_i$.

In \ref{sec:heat_diffusion}, we show that the diffusion of heat on a graph can be expressed as the convolution of an initial condition $f$ with a heat kernel $h$. It should hopefully shed some light on the meaning of the convolution on a graph.

\subsection{Efficient convolutions}
\label{sec:efficient_convolution}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{filtering_speed}
    \caption{Comparison of filtering speed for Gaussian smoothing of maps of various sizes.
    The fast spherical harmonic transform (SHT) is implemented by the \texttt{healpy} Python package (via the \texttt{healpy.sphtfunc.smoothing} function with $\ell_{max} = 3 N_{side} - 1$, the default).
    The graph filtering is defined by \eqnref{graph_convolution_cheby} and implemented with the \texttt{numpy} and \texttt{scipy} Python packages.
    Both are executed on a single core.
	The theoretical cost of filtering on the graph is $\bO(K N_{pix})$ and $\bO(\ell_{max}^3) = \bO(N_{pix}^{3/2})$ for the spherical harmonics, where $\ell_{max}$ is the largest angular frequency.}
    \label{fig:filtering_speed}
\end{figure}

While \eqnref{graph_convolution_fourier} is a theoretically well justified definition of the convolution of a graph signal $\f$ by a kernel $h$, it is computationally cumbersome.
As no general Fast Fourier Transform (FFT) exist for graphs, the execution of the Fourier transform by multiplication of the signal $\f$ by the dense matrix $\U$ costs $\bO(N_{pix}^2)$ operations.
% \footnote{See \citep{le2018fgft} for a comparison between the polynomial definition of filters presented here and a class of fast graph Fourier transforms based on the approximation of the Fourier basis $\U$ by a product of sparse matrices.}
%\TK{I would just cite the paper, we have not introduced the polynomials at this stage yet.}
In a CNN, this operation has to be performed for each training step: forward and backward.
% As current training procedures are not data-efficient and require a lot of samples, a quadratic computational cost in the sample size is a .
%\TK{what does "data-efficient mean"? removing for now}
As current training procedures require processing of many samples, it would be very slow to perform them for a quadratic computational cost in the sample size.
Moreover, the eigen-decomposition of the Laplacian $\L$ is needed to obtain the Fourier basis $\U$ in the first place.
That has a unique cost of $\bO(N_{pix}^3)$ operations.

Fortunately, both of these computational issues can be overcome by defining the convolution kernel $h$ as a polynomial $h_\theta(\lambda) = \sum_{k=0}^K \theta_k \lambda^k$ of degree $K$ parametrised by $K+1$ coefficients $\theta$.
In that specific case, the filtering operation \eqnref{graph_convolution_fourier} becomes
\begin{equation} \label{eqn:graph_convolution_monomial}
	h_\theta(\L) \f =  \U \left(\sum_{k=0}^K \theta_k \bLambda^k \right) \U\trans \f = \sum_{k=0}^K \theta_k \L^k \f,
\end{equation}
an operation requiring $k$ multiplications of the graph Laplacian matrix $\L$.
In our case, the Laplacian is extremely sparse, with $8-9$ entries per line, making the filtering operation for a fixed $K$ linear in the number of pixel $N_{pix}$.
% Moreover, here happens the transition from filtering in the spectral domain to filtering in the vertex domain.
This operation is performed in the vertex domain.
The matrix $\L^k$ captures $k$-neighborhoods of each pixel, i.e., $(\L^k)_{ij}$ is non-zero if and only if nodes $v_i$ and $v_j$ are connected by a path of length $k$.
As such, filtering with a polynomial convolution kernel can be interpreted in the pixel (vertex) domain as a weighted linear combination of the pixels neighbors values. The weights are determined by the filter coefficients $\theta$ and the Laplacian $\L$.
We note that restricting the graph convolutional kernel to a polynomial is similar to restricting the classical Euclidean signal-domain convolution to a patch. In the classical setting, the convolution with a patch is simply a weighted sum of the neighbors with the weights defined by the patch. Similarly, each lines of the matrix $\sum_{k=0}^K \theta_k \L^k$ defines an "irregular patch of radius $K$" for our irregular domain.
% \todo{Better vertex domain explanation.
% \nati{I gave it a try. Should we take a single vertex and explain what heppens to it? Note that I suppressed the following paragraph. }}
% \TK{For me it's understandable:)}

% To make the parallel with classical Euclidean signal-domain convolution, i.e., filtering by multiplying the signal with translated versions of a patch, we here match our filter at the level of neighborhoods\footnote{The 1-neighborhood of a node is the set of nodes which are directly connected to it. The 2-neighborhood is the set of nodes which are connected through paths of length 2.} rather than individual nodes. That is required as there is no notion of ordering in a general graph. For example, in a classical convolution on the grid, the relative ordering of vertices is up, down, left, and right. There is no such ordering on the sphere either, especially if irregularly sampled.

Following \citet{defferrard2016convolutional}, we define our filters as Chebyshev polynomials such as the convolution operation becomes
\begin{equation} \label{eqn:graph_convolution_cheby}
	h_\theta\left(\tL\right) \f = \U \left(\sum_{k=0}^K \theta_k T_k\left(\tilde{\bLambda}\right) \right) \U\trans \f = \sum_{k=0}^K \theta_k T_k\left(\tL\right) \f,
\end{equation}
where $\tL = \frac{2}{\lambda_{max}} \L - \b{I} = -\frac{2}{\lambda_{max}} \D^{-1/2} \W \D^{-1/2}$ is the rescaled Laplacian with eigenvalues $\tilde{\b \Lambda}$ in $[-1, 1]$ and $T_k(\cdot)$ is the Chebyshev polynomial of degree $k$, defined by the recursive relation $T_k(\tL) = 2\tL T_{k-1}(\tL) - T_{k-2}(\tL)$, $T_1(\tL) = \tL$, $T_0(\tL) = \b{I}$. While definitions \eqnref{graph_convolution_monomial} and \eqnref{graph_convolution_cheby} both allow the representation of the same set of filters, Chebyshev polynomials are preferred as they form an orthogonal basis on the interval $[-1, 1]$. Moreover, they factor out $\tL^{k-2}$ from $T_k(\tL)$, e.g., the 3-neighborhood is not mixed with the 5-neighborhood. That results in easier learning when optimizing the parameters $\theta$.
Finally, the coefficients can be computed such as the truncated Chebyshev expansions gives an approximate minimax polynomial of a given filter \citep{hammond2011wavelets}. While that is irrelevant when learning filters, it is useful when smoothing a signal on the sphere by filtering it with an approximated low-pass filter.
In practice, we found out in our experiment that Chebyshev polynomials are slightly more stable than the monomials used in~\cite{khasanova2017graphomni}(i.e. optimizing directly the $\theta_k$ in \eqnref{graph_convolution_monomial}).
We believe that this is due to their orthogonality (as explained above) and uniformity\footnote{The amplitude of Chebyshev polynomials is more or less constant over the domain $[-1, 1]$ independently of the order $k$. On the contrary the amplitude of $x^k$ is very different for $|x|\approx 0$ and $|x| \approx 1$.}.
% \nati{I added a sentence and I think we should not give much more details here. If we do an experiment, we can comment in the experiment section.}
% \todo{(i) scale of $\theta_k$: they are mostly uniform for Chebyshev polynomials, end exploding for monomials. Though SGD implicitly imposes a uniform prior on the learned parameters.}
% \todo{(ii) numerical stability of $\L^k \f$ v.s. $T_k(\L) \f$}
% \todo{(iii) in the code, initialize $\theta_k$ with stdev adapted to $F_{in}$ and $K$}

Exploiting the recursive formulation of Chebyshev polynomials, evaluating \eqnref{graph_convolution_cheby} requires $\bO(K)$ multiplications of the dense vector $\f$ with the sparse matrix $\tL$.
The cost of one such multiplication is $\bO(|\E|)$. By construction of our graph, $|\E| < 8 N_{pix}$ and the overall computational cost of the convolution is thus reduced to $\bO(N_{pix})$ operations.
That is much more efficient than filtering with spherical harmonics, even though the HEALPix was designed as an iso-latitude sampling to leverage a fast spherical transform.
That is especially true for smooth kernels which require a low polynomial degree $K$.
\figref{filtering_speed} compares the speed of low-pass filtering for Gaussian smoothing using the spherical harmonics and the graph-based method presented here.
A naive implementation of our method is ten to twenty times faster for $N_{side} = 2048$, with $K=20$ and $K=5$, respectively, than using the spherical harmonic transform implemented by the highly optimized library used by HEALPix, \pkg{libsharp} \citep{reinecke2013libsharp}.

\subsection{Coarsening and Pooling}

Coarsening can be naturally designed for hierarchical pixelisation schemes, as each subdivision divides a cell in an equal number of child sub-cells.
Coarsening is the reverse operation: merging the sub-cells toward the goal of summarizing the data supported on them.
Merging cells lead to a coarser graph.
Coarsening defines $\C(i)$, the set of children of node $v_i$.
For the HEALPix subdivision scheme, the number of children is constant, i.e., $| \C(i) | = 4^p \ \forall i$, for some $p$.

Pooling refers to the operation that summarizes the data supported on the merged sub-cells in one parent cell.
Given a map $\x \in \R^{N_{pix}}$, pooling defines $\y \in \R^{N'_{pix}}$ such as
\begin{equation} \label{eqn:pooling}
	y_i = f \left( \left\{ x_j : j \in \C(i) \right\} \right), \ \forall i \in [N'_{pix}],
\end{equation}
where $f$ is a function which operates on sets (possibly of varying sizes) and $N_{pix} / {N'_{pix}}$ is the down-sampling factor, which for HEALPix is $| \C(i) | = N_{pix} / {N_{pix}}' = (N_{side} / N'_{side})^2 = 4^p$.
That operation is often taken to be the maximum value, but it can be any permutation invariant operation, such as a sum or an average.
\figref{pooling} illustrates the process.

% The advantage of schemes based on a base polyhedron is that cells are equal-area. While that is not required for the convolution operation when modeling with graphs (it can be corrected by setting edge weights appropriately, see \citet{khasanova2017graphomni})
% nope: can also do a regular pooling on the equirectangular. It preserves the sampling, and the convolution is adapted to the sampling thanks to the edge weights.

\begin{figure}
	\centering
    % \includegraphics[width=\linewidth]{pooling}
	\includegraphics[trim=1.1cm 0cm 0cm 0cm, width=\linewidth]{figures/figure_pooling_svg.pdf}
	\caption{Two levels of coarsening and pooling: groups of 4 cells are merged into one, then the data on them is summarized in one. The coarsest cell covers $1/12$ of the sphere.}
	\label{fig:pooling}
\end{figure}

\subsection{Statistical layer}
\label{sec:stat_layer}
% Or Global pooling?

Following \citet{khasanova2017tigranet}, we implement an optional statistical layer between the last graph convolutional layer and the first fully connected layer for the neural network.
This introduces the invariance of the output to isometric transformations, such as rotation of maps on the sphere.
The role of the layer is to compute global and location independent statistics from feature maps.
Besides providing invariance, the layer drastically compresses the representation of the data as the number of computed statistics $N_{stat}$ is usually much smaller than the size of the map $N_{pix}$. That compression results in much smaller fully connected layers, which usually contain a significant fraction of trainable parameters of a neural network.
The invariance and reduced representation should help the network to learn from fewer samples and to generalize better to unseen data. Yet another advantage is that a network built with such a statistical layer is agnostic to the size of the input data, i.e., it can classify maps which do not have the same number of pixels. Indeed, such global summarization is invariant to node permutation and is commonly used along graph convolutions to classify graphs of varying sizes \citep{duvenaud2015gcn, li2015gatedgnn}.

Given a feature map $\x \in \R^{N_{pix}}$, the statistical layer is defined as
\begin{equation} \label{eqn:stat_layer}
	\y = f(\x) \in \R^{N_{stat}},
\end{equation}
where $f$ computes $N_{stat}$ statistics which are independent from the size of the map, $N_{pix}$. An example is the global average pooling $f(\x) = \esp(\x)$, introduced by \citet{lin2013globalavgpooling}, where $\esp(\x) = \frac{1}{N_{pix}} \sum_{i=1}^{N_{pix}} x_i$ is the empirical mean. Another example is $f(\x) = [\esp(\x), \var(\x)]\trans$, where $\var(\x) = \frac{1}{N_{pix}} \sum_{i=1}^{N_{pix}} (x_i - \esp(\x))^2$ is the empirical variance.
Other statistical layers are also possible.
In particular, we also implement a \emph{learned histogram} statistic \citep{wang2016learnhist}.
Other approaches, which we did not implement, may include applying different diffusion on the final maps to obtain statistics at different scales, as proposed by \citep{khasanova2017tigranet}.

\subsection{Graph convolutional neural network}
\label{sec:architecture}

Neural networks are constructed as stacks of layers which sequentially transform the data from its raw representation to a decision on the class label. Our architecture, pictured in \figref{architecture}, is composed of many layers. The convolutional part, the head of the neural network, is composed of graph convolutional layers (GC), pooling layers (P), and batch normalization layers (BN). The tail is composed of multiple fully connected layers (FC) followed by a softmax layer (SM). A statistical layer (ST) is optionally inserted between the convolutional head and the fully connected tail.

% As such, we will not mention the non-linearity in the description of our architectures.
A non-linear function $\sigma(\cdot)$ is applied after every linear GC and FC layer, except for the last FC layer where it is set to the identity. That operation is point-wise, i.e., $y_{ij} = \sigma(x_{ij})$ and $y_i = \sigma(x_i)$ for matrices $\X, \Y$ and vectors $\x, \y$. The rectified linear unit (ReLU) $\sigma(\cdot) = \max(\cdot, 0)$ is a common choice.

Given a matrix $\X = [\x_1, \ldots, \x_{F_{in}}] \in \R^{N_{pix} \times F_{in}}$, a GC layer computes $\Y = GC(\X) = [\y_1, \ldots, \y_{F_{out}}] \in \R^{N_{pix} \times F_{out}}$, where $N_{pix}$ is the number of pixels (and nodes), $F_{in}$ is the number of input features, and $F_{out}$ is the number of output features.
Using the efficient graph convolution from \eqnref{graph_convolution_cheby}, each output feature map is computed as
\begin{equation*}
	\y_i = \sum_{j=1}^{F_{in}} h_{\theta_{ij}}(\tL) \x_j + b_i \in \R^{N_{pix}}, \ \ \forall i \in [F_{out}].
\end{equation*}
As such, a GC layer is composed of $F_{in} \cdot F_{out}$ filters, each parameterized by $K$ numbers (see \secref{efficient_convolution}). A bias term $\b b \in \R^{F_{out}}$ is jointly optimized.
% only if batch normalization is not used

Given a matrix $\X \in \R^{N_{pix} \times F}$, a pooling layer computes $\Y = P(\X) \in \R^{N'_{pix} \times F}$ by reducing its spatial resolution ($N'_{pix} < N_{pix}$) according to \eqnref{pooling}.
% Given a matrix $\X \in \R^{N_{pix} \times F}$,
The batch normalization layer \citep{ioffe2015batchnorm} computes $\Y = BN(\X)$ such as
\begin{equation*}
	\y_i = \gamma_i \frac{\x_i - \esp(\x_i)}{\sqrt{\var(\x_i) + \epsilon}} + \beta_i, \ \forall i \in [F],
\end{equation*}
where $\gamma_{j}$ and $\beta_{j}$ are parameters to be learned and $\epsilon$ is a constant added for numerical stability. The empirical expectation $\esp(\x_i) \in \R$ and variance $\var(\x_i) \in \R$ are taken across training examples and pixels.
% the action of gamma can be done by the filters of the next layer

The statistical layer, defined in \eqnref{stat_layer}, independently transforms each of the $F$ feature maps of the input $\X \in \R^{N_{pix} \times F}$ into $\Y = ST(\X) \in \R^{N_{stat} \times F}$, where $N_{stat}$ is the number of statistics. One may even omit the FC layers and directly fed the output of the ST layer into the softmax layer, as proposed by \citet{lin2013globalavgpooling}. In this regime, $N_{stat} = 1$ and $F = N_{classes}$ is the number of classes to discriminate (i.e., the last GC layer outputs as many feature maps as there is classes).

A FC layer takes as input $\x \in \R^{F_{in}}$ and outputs
\begin{equation*}
	\y = FC(\x) = \b W \x + \b b \in \R^{F_{out}} ,
\end{equation*}
where $\W \in \R^{F_{out} \times F_{in}}$ and $\b b \in \R^{F_{out}}$ are the parameters to be learned.
Note that the output $\Y \in \R^{N_{pix} \times F_{out}}$ of the last GC (or the output $\Y \in \R^{N_{stat} \times F_{out}}$ of the ST), is vectorized as $\x = \vect(\X) \in \R^{F_{in}}$ before being fed to the first FC, where $F_{in} = N_{pix} \cdot F_{out}$ (or $N_{stat} \cdot F_{out}$).

The softmax layer is the last layer in a neural network engineered for classification. Given the output $\x \in \R^{N_{classes}}$ of the last FC (or ST), called the logits in the deep learning literature, the softmax layer outputs $\y = SM(\x)$ such that
\begin{equation*}
	y_i = \frac{\exp(x_i)}{\sum_{j=1}^{N_{classes}} \exp(x_j)} \in [0, 1], \ \forall i \in [N_{classes}],
\end{equation*}
where $N_{classes}$ is the number of classes to discriminate. Thanks to the softmax, the output $\y \in \R^{N_{classes}}$ of a neural network is a probability distribution over the classes, i.e., $y_i$ is the probability that the input sample belongs to class $i$. This last layer is actually normalizing $\x$ into $\y$ such that $\| \y \|_1 = \sum_i y_i = 1$.

Given a map $\X \in \R^{N_{pix} \times F_{in}}$, a neural network for global prediction is computing $\y = NN_\theta(\X) \in R^{F_{out}}$, where $NN$ is a composition of the above layers and $\theta$ is the set of all trainable parameters.
Two example networks for global classification, a CNN and a FCN, are
\begin{align*}
	NN &= SM \circ FC \circ \sigma \circ FC \circ \sigma \circ GC \circ P \circ \sigma \circ BN \circ GC, \\
	NN &= \underbrace{SM \circ ST \circ \sigma \circ GC}_{\text{classifier}} \circ \underbrace{\sigma \circ GC \circ P \circ \sigma \circ BN \circ GC}_{\text{feature extractor}},
\end{align*}
where $\circ$ denotes composition, i.e., $(f \circ g)(x) = f(g(x))$.
The number of features $F_{in}$ depends on the data at hand. For the CMB radiation temperature, $F_{in} = 1$. For observations in radio frequencies, $F_{in}$ would be equal to the number of surveyed frequencies. $F_{in}$ might also be the number of slices in the radial direction. The number of predictions $F_{out}$ is either equal to the number of classes $N_{classes}$ for a classification task, or the number of variables to be predicted for a regression task. A typical global classification task is to classify maps into cosmological model classes \citep{schmelze2017cosmologicalmodel}. A typical global regression task is to infer the parameters of a cosmological model  from maps \citep{fluri2018deep,gupta2018nongaussianinformation}.
Dense prediction, i.e., predicting $F_{out}$ values per pixel, is obtained by omitting ST and FC layers (P layers, if used, have to be inverted via up-sampling in an encoder-decoder architecture). An example network for dense regression is
\begin{equation*}
	\Y = NN(\X) = (GC \circ \sigma \circ BN \circ GC)(\X) \in \R^{N_{pix} \times F_{out}}.
\end{equation*}
Such networks are useful for (i) dense regression, such as denoising a map, interpolating missing values, or predicting a density map given the CMB, or (ii) dense classification, such as segmenting galactic clusters in a \todo{xx} map. \todo{TK: please find better cosmological applications. Maybe some refs?} We emphasize that the use of FC and ST layers is the sole difference between a neural network engineered for global or dense prediction.

The cost (or loss) function $C(\Y, \bar \Y) = C(NN_\theta(\X), \bar \Y)$ measures how good the prediction $\Y$ is for sample $\X$, given the ground truth $\bar \Y$. For a classification task, the cost is usually taken to be the cross-entropy
\begin{equation*}
	C(\Y, \bar \Y) = - \sum_{i=1}^{N_{pix}} \sum_{j=1}^{N_{classes}} \bar y_{ij} \log(y_{ij}),
\end{equation*}
where $\bar \Y \in \R^{N_{pix} \times N_{classes}}$ is the ground truth label indicator, i.e., $\bar y_{ij} = 1$ if pixel $i$ of sample $\X$ belongs to class $j$ and is zero otherwise. For global prediction, the cost is as if $N_{pix} = 1$.
For a regression task, a common choice is the mean squared error (MSE)
\begin{equation*}
	C(\Y, \bar \Y) = \frac{\|\Y-\bar{\Y}\|_2^2}{N_{pix} F_{out}} = \frac{1}{N_{pix} F_{out}} \sum_{i=1}^{N_{pix}} \sum_{j=1}^{F_{out}} (y_{ij} - \bar y_{ij})^2,
\end{equation*}
where $\bar{\Y}$ is the desired output. Again, take $N_{pix} = 1$ for global regression. We emphasize that the cost function and the SM layer is the sole difference between a neural network engineered for classification or regression.

The goal of learning is to find the parameters $\theta$ of the neural network that minimize the risk $R(\theta) = \esp \left[ C \left( NN_\theta(\X), \bar \Y \right) \right]$. In general, that expectation cannot be computed as the data distribution is unknown. We can however minimize an approximation, the empirical risk over the training set $\left\{ \left( \X_i, \bar \Y_i \right) \right\}_{i=1}^{N_{samples}}$:
\begin{equation*}
	\hat{\theta} = \argmin_\theta \sum_{i=1}^{N_{samples}} C \left(NN_\theta(\X_i), \bar \Y_i \right).
\end{equation*}
The optimization is performed by computing an error gradient w.r.t.\ all the parameters by back-propagation and updating them with a form of stochastic gradient descent (SGD):
\begin{equation*}
	\theta \leftarrow \theta - \frac{\eta}{|\B|} \sum_{i \in \B} \frac{\partial C \left( NN_\theta(\X_i), \bar \Y_i \right)}{\partial \theta} ,
\end{equation*}
where $\eta$ is the learning rate, and $\B$ is the set of indices in a mini-batch. Batches are used instead of single samples to gain speed by exploiting the parallelism afforded by modern computing platforms.


\section{Related work}
\label{sec:related}

\begin{figure}
    \centering
    \includegraphics[height=7em]{sphere_grid_equirectangular}
    \hfill
    \includegraphics[height=7em]{sphere_grid_cubedsphere}
    \hfill
    \includegraphics[height=7em]{half_graph_4}
    \caption[]{Some pixelizations of the sphere. Left: the equirectangular grid, using equiangular spacing in a standard spherical-polar coordinate system. Middle: an equiangular cubed-sphere grid, as described in \citet{ronchi1996cubed}. Right: graph built from an HEALPix pixelization of half the sphere ($N_{side} = 4$). By construction, each node has 8 neighbors, except the highlighted ones which have only 7.\footnotemark[7] Left and middle figures are taken from \citet{boomsma2017spherical}.}
    \label{fig:sphere_grids}
    \label{fig:healpix_graph_4}
\end{figure}

A first approach, explored by \citet{boomsma2017spherical} for molecular modeling and \citet{su2017sphericalconv, coors2018spherenet} for omnidirectional imaging, is to use a 2D CNN on a discretization of the sphere that is a grid, such as the equirectangular projection (\figref{sphere_grids} left), or a set of grids, such as the cubed-sphere defined by~\citet{ronchi1996cubed} (\figref{sphere_grids} middle).
As this formulation uses the standard 2D convolution, all the optimizations developed for images can be applied, what makes it computationally efficient.
This approach is applicable to the many pixelizations that are based on a regular subdivision of a base polyhedron, such as HEALPix. Each base polyhedron then forms a grid.
Care has to be taken to handle boundary conditions: for example by padding a grid with the content of the opposite side (equirectangular) or of the neighboring grids (cubed-sphere, HEALPix). That incurs some computational losses.
For samplings that are not equal area, such as the equirectangular projection, the convolution operation can be adjusted to take the induced distortion into account \citep{su2017sphericalconv, coors2018spherenet}.
% Furthermore, the grid requirement makes it impossible for the convolution to capture the spherical properties of the domain, i.e., the cubed-sphere sampling is by definition adapted to a cube and not to a sphere. Nope, the graph can adapt to any sampling.

Another approach to leverage 2D CNNs is to project spherical data onto many tangent planes, which are flat 2D surfaces. This approach has been extensively used for cosmological maps \citep{fluri2018deep, gupta2018nongaussianinformation, schmelze2017cosmologicalmodel, gillet2018deeplearning} and omnidirectional imaging \citep{xiao2012recognizing, zhang2014panocontext}. This idea has been generalized to arbitrary 2D manifolds for shape alignment and retrieval \citep{masci2015gcnn, boscaini2016acnn, monti2017monet}.

The main issue with the above two approaches is that they depend on a (local) coordinate system to define anisotropic filters, i.e., filters which are direction dependent. Direction is well defined and matters for some applications, such as the analysis of weather and climate data on the Earth (north, south, east, west), and omnidirectional imaging (up, down). Indeed, full rotation invariance has been shown to reduce discriminative power for omnidirectional imaging \citep{coors2018spherenet}. Some problems are, however, intrinsically invariant to rotation, such as the analysis of cosmological maps, or the modeling of atoms and molecules. In such cases, directions are arbitrarily defined when setting the origin of the pixelization. A rotation equivariant convolution, i.e., a rotation of the input implies the same rotation in the output, thus has to be isotropic.

% Moreover, when different grids require different filters as their orientation is not compatible.
% => same as for tangent planes

\citet{cohen2018sphericalcnn} and \citet{esteves2017sphericalcnn} addressed the problem of rotation equivariance leveraging the convolution associated to the 3D rotation group SO(3), with applications to atomization energy regression and 3D model classification, alignment and retrieval.
The resulting convolution is performed by (i) a spherical harmonic transform (SHT), i.e., a projection on the spherical harmonics, (ii) a  multiplication in the spectral domain, and (iii) an inverse SHT. Hence the computational cost of a convolution is dominated by the two SHTs.
A naive implementation of the SHT costs $\bO(N_{pix}^2)$ operations, where $N_{pix}$ is the number of pixels. Note the similarity with the naive graph convolution defined in \eqnref{graph_convolution_fourier}.
Accelerated schemes exist for some sampling sets \citep[see][for examples]{mohlenkamp1999fast, rokhlin2006fast, reinecke2013libsharp}.
The main advantage of this approach is that it provides a mathematically well-defined rotation-equivariant network. Nevertheless, even with accelerated SHTs, the convolutions remain expensive, limiting the practical use of this approach.
For example, with the HEALPix sampling, which was designed to have a fast SHT by being iso-latitude, the computational cost of the SHT is $\bO(N_{pix}^{3/2}) = \bO(N_{side}^3) = \bO(\ell_{max}^3)$, where $\ell_{max}$ is the largest angular frequency\footnote{All pixels are placed on $N_{ring} = 4N_{side}-1 = \bO\left(\sqrt{N_{pix}}\right)$ rings of constant latitude. Each ring has $\bO\left(\sqrt{N_{pix}}\right)$ pixels. Thanks to this iso-latitude property, the SHT is computed using recurrence relations for Legendre polynomials on co-latitude and fast Fourier transforms (FFTs) on longitude. The computational cost is thus $\sqrt{N_{pix}}$ FFTs for a total cost of $\bO\left( N_{pix} \log \sqrt{N_{pix}} \right)$, plus $\sqrt{N_{pix}}$ matrix multiplications of size $\sqrt{N_{pix}}$ for a total cost of $\bO\left(N_{pix}^{3/2}\right)$.}
\citep{gorski2005healpix, reinecke2013libsharp}.
In comparison, filtering with our HealpixNet method scales as $\bO(N_{pix})$ (see \secref{efficient_convolution}).
\citet{kondor2018clebsch} proposed to use the Clebsh-Gordan transform to perform a non-linear transformation in the spectral domain. As such, a SHT only has to be performed once at the input of the network and the back and forth SHT between every layer is no longer required. While this clever trick makes the convolution complexity $\bO(N_{pix})$, the non-linearity scales, to the best of our understanding, as  $\bO(N_{pix}^{3/2})$. At the time of writing this paper, computation time is unfortunately not reported, hence making unclear which speed gain is obtained in practice. 
While the convolution in the spectral domain avoid all sampling problems, one of its downsides might the lack of natural locality, a property that is naturally obtained by the polynomial approach of graph convolution. Because the convolution is at the begging of the neural network, we believe that is should focus on local correlations first before exacting more complex structures.
%\todo{Polynomial formulation enforces locality, which otherwise has to be enforced by smoothness in the spectral domain.}
%\todo{Pooling in the spectral domain? \citet{esteves2017sphericalcnn} do something.}
% While a comparison is theoretically possible, the experiments of~\cite{cohen2018sphericalcnn} are done using the geodesic grid sampling set and do not provide any code for the HEALPix one. Hence, a practical comparison is not possible.

All the above methods cannot easily be accelerated when the data lies on a part of the sphere only.
That is, however, an important use case in cosmology as measurements are often partial, i.e., full-sky maps are rare.
One could still fill the unseen part of the sphere with zeros, and avoid computing empty integrals.
% on the latitude or longitude for SHTs, on square holes for 2D CNNs
It is, however, not straightforward to identify empty space, and computations would still be wasted; consider, for example, a ring which mostly contains zeros but a few measurements.
With graphs, however, the computation is done only for the used pixels.
While it results in some distortions due to border effects (see \figref{border_effects} and \ref{sec:border_effects}), these can be mitigated by padding with zeros a small area around the measurements.

The use of a graph to model the discretised sphere was also considered by \citet{khasanova2017graphomni} for omnidirectional imaging.
% The authors map omnidirectional images onto a sphere, with the goal of correcting for distortions induced by the lens, which was used for their acquisition.
% First, similarly to~\citet{boomsma2017spherical}, they use an equirectangular grid sampling.
This work is the closest to our method, with three differences. First, they parametrize their convolution kernel with \eqnref{graph_convolution_monomial} instead of \eqnref{graph_convolution_cheby} (see \secref{efficient_convolution} for a discussion and comparison).
Second, they did not take advantage of a hierarchical pixelization of the sphere and resorted to dynamic pooling \citep{kalchbrenner2014dcnn}. While that operation is useful for sequences of varying length, such as sentences in language models, it is overkill in our context as it is not local and destroys spatial coherence.
Third, they introduced a statistical layer --- an operation that computes a set of statistics from the last feature maps --- to provide full rotation invariance. We propose to use the idea of fully convolutional networks (FCNs) instead (see \secref{selected_architecture}). While statistics have to be hand-chosen to capture relevant information for the task, the filters in a FCN are trained end-to-end to capture relevant information.

The connection has been made between graph CNNs and group equivariant CNNs by \citet{kondor2018equivariance}, justifying the use of graphs to gain rotation equivariance on the sphere. 
\todo{More here.}

Many formulations of graph neural networks, reviewed by \citet{bronstein2017review} and \citet{hamilton2017review}, have been proposed. For this contribution, we chose the formulation of \citet{defferrard2016convolutional} as its root on strong graph signal processing theory makes the concept of convolutions and filters explicit \citep{shuman2013emerging}. As the convolution is motivated by a multiplication in the graph Fourier spectrum, it is close in spirit, and empirically, to the formulation based on the spherical harmonics, which is the ideal rotation equivariant formulation.
% and study its equivariance properties.

% Main interpretations: GSP, Bronstein manifold tangent plane, message passing, permutation invariant aggregation, spatial ordering and matching

Thanks to their versatility, graph neural networks have been used in a variety of tasks, such as identifying diseases from brain connectivity networks \citep{ktena2018metriclearning} or population graphs \citep{parisot2017disease}, designing drugs using molecular graphs \citep{hop2018drugdesign}, segmenting 3D point clouds \citep{qi2017pointcloudsegmentation}, optimizing shapes to be aerodynamic \citep{baque2018shape}, and many more.
By interwinding graph convolutional layers and recurrent layers \citep{seo2016gcrn}, they can for example model structured time series such as traffic on road networks \citep{li2018traffic}, or recursively complete matrices for recommendation \citep{monti2017recommendation}.
Another trend, parallel to the modeling of structured data, is the use of graph neural networks for relational reasoning \citep{battaglia2018review}.
% scientifically and industrially motivated applications

\section{Experiments}
\label{sec:experiments}

% Structure of the section
% 1) Present the goal
% 2) Explain briefly the dataset
% 3) Present the setting
% 4) Describe the result
In this section we demonstrate the performance of the spherical neural network on a discrimination problem: the classification of convergence maps into two cosmological model classes.
These maps are similar to those created with gravitational lensing technique \citep{chang2017curvedsky}.
The experiment presented here is similar the one by \citet{schmelze2017cosmologicalmodel}.
The two sets of maps were created using the standard cosmological model with two sets of cosmological parameters.
The classification methods were trained to assign a predicted label using the HEALPix maps.
Both our Python implementation\footnote{\url{https://github.com/SwissDataScienceCenter/HealpixNet}} and the data\footnote{\url{https://doi.org/10.5281/zenodo.1303272}} to reproduce those experiments are available online.

We use the classification scenario in this work.
Extensions to other tasks, such as regression or segmentation, is also possible; we do not, however, demonstrate it here.
The regression task will most likely be the most practical cosmological applications, as described in \citep{gupta2018nongaussianinformation,fluri2018deep}.
Implementation of full cosmological inference requires, however, many more simulations, building the likelihood function, and several other auxiliary tasks.
The classification problem is much more straightforward to implement and execute, and can be used to fairly compare the accuracy of the algorithm against benchmarks \citep{schmelze2017cosmologicalmodel}.
For these reasons we decided to use the classification problem in this work, and we expect the relative performance of the methods to generalise to the regression scenario.


\subsection{Data}
\label{sec:data}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{psd_sigma3}
\caption{Power spectrum densities of the noiseless maps.
The maps have been smoothed with a Gaussian kernel of radius $3$ arcmins to remove high frequencies.
The cosmological models could otherwise have been distinguished by the power spectra alone.}
\label{fig:psd_sigma3}
\end{figure}


\begin{figure*}
\centering
% \includegraphics[width=0.75\linewidth]{smooth_map_class_1}
% trim=left botm right top
\includegraphics[trim=1cm 0cm 0cm 0cm, width=0.49\linewidth]{figures/figure_kappa_diff_model1.pdf}
% \hfill
% \includegraphics[width=0.75\linewidth]{smooth_map_class_2}
\includegraphics[trim=0cm 0cm 1cm 0cm, width=0.49\linewidth]{figures/figure_kappa_diff_model2.pdf}
\caption{Example maps from two classes to be discriminated. Left: model 1 with $\Omega_m=0.31$ and $\sigma_8=0.82$. Right: model 2 with $\Omega_m=0.26$ and $\sigma_8=0.91$.
The initial conditions for both simulations were the same, so differences only arise due to different cosmological parameters. \nati{Tomek: Is this correct?}}
\label{fig:map_sample}
\end{figure*}


Convergence maps represent the dimensionless distribution of over- and underdensities of mass in the universe, projected on the sky plane.
The 3D structures are projected using a geometric kernel, value of which depends on the radial distance.
In gravitational lensing, this kernel is dependent on the radial distances between the observer, the mass plane and the plane of source galaxies \citep[see][for review of gravitational lensing]{bartelman2010gravitationallensing}.
The redshifts of the sources was set to $z=1$.

We make full sky N-body simulations for two parameter sets for $\Lambda\rm{CDM} $ cosmological model: model 1 ($\Omega_m=0.31, \sigma_8=0.82$) and model 2 ($\Omega_m=0.26, \sigma_8=0.91$), where $\Omega_m$ is the matter density in the universe and $\sigma_8$ is the normalisation of the matter power spectrum.
Other parameter parameters were set to: Hubble constant $H_0=70 km/s/Mpc$, spectral index $n_s=0.96$, and Baryon density today $\Omega_b=0.05$.
The parameters $\Omega_m$ and $\sigma_8$ were chosen to have the same spherical harmonic power spectrum for $\ell<1000$.
That means that it is very difficult to distinguish between these cosmological models using these maps if this range of scales is used.
We found that for $\ell>1000$ the differences in power spectrum is $~5\%$.
To remove this information, we additionally smooth the spherical maps with a Gaussian kernel of radius $3$ arcmin.
The resulting Power Spectrum Density (PSD), computed using the \texttt{anafast} function in the HEALPix package, are displayed in \figref{psd_sigma3}.
In the pre-processing step, we also remove the mean of each map and down-sample them to a resolution of of $N_{side}=1024$.


The simulations are created using the fast lightcone method described in~\citep{sgier2018fastgeneration}.
However, we use only a single simulation box, as opposed to two used in that work, as we use source galaxies at lower redshift of $z=1$, instead of $z=1.5$.
As a simulator we use \pkg{L-PICOLA} \citep{howlett2015lpicola}, a fast and approximate code for N-body simulations.
For each class, we generate $30$ simulations, with both classes having the same initial parameters.

Out of the $60$ simulations, $20$ are kept as the test set.
\figref{map_sample} shows the full sky simulations and a zoom region for model 1 (top) and model 2 (bottom).
Initial conditions for these simulations were the same, so the differences in structures can only be attributed to different cosmological parameters used to evolve the particle distribution.



\subsection{Problem formulation}
While the number of maps might sound small for deep learning, the information contained in the maps is very recurrent, allowing us to use parts of the map as samples for our simulation.
Using the properties of the HEALPix sampling, we can split each maps into $12*o^2$ ($o=1,2,4,\dots$) samples that span a smaller part of the sphere.
% As shown in \figref{part_sphere}, we used $o=1,2,4$ as the resulting samples are large enough to suffer from the effects of the spherical geometry.
The resulting maps are large enough to suffer from the effects of the spherical geometry, and cover 8.3\%, 2.1\% and 0.5\% of the total sphere area for $o=1,2,4$, respectively.
The areas on the sphere corresponding to these orders can be seen in \figref{pooling}: the pixels in the left, middle and right spheres correspond to $o=4,2,1$, respectively.
We decided to only report simulation results for this specific setting as spherical cosmological data usually does not span the full sphere.
Nevertheless, our code includes an example using the full sphere.

% \begin{figure}
% \centering
% \includegraphics[width=\linewidth]{part_sphere}
% \caption{Three parts of the sphere with different sizes. Blue: $o=1$. Green: order $o=2$. Yellow: order $o=4$.}
% \label{fig:part_sphere}
% \end{figure}
For all the experiments, we work with centered Gaussian noise.
While the noise model of real mass maps often has a slightly different distribution, Gaussian should be a sufficient model to demonstrate the performance of our method.
The noise added to our maps had levels spanning the range between 0 and 2  $\times$ the standard deviation of the mass maps.

We build a robust classifier, which automatically discriminates between the two classes in the presence of noise.
We check the classification performance as a function of the area used, the order $o$, and the relative level of the noise added to the map.

% Nati: Not done anymore
% To improve the stability of the spherical CNN, we slowly increase the amount of noise added to the training data over the iterations.
Furthermore in order to avoid over-fitting, the noise is randomly produced during the training process.
The $20\%$ of the training set that we call \emph{validation set} was left out of the training process and simply used to assess the global performance of the network.


We compare the performance of the spherical CNN against two simple benchmark algorithms.
The two baselines are based on building features with
(a) the Power Spectral Densities (PSD) and
(b) the histogram of pixels in the maps~\cite{patton2017cosmologicalconstraints}.
After a normalization, those features are then classified using a Support Vector Machine (SVM) with a linear kernel.
Other kernels did not provide better results, while having significantly worse scaling properties.
All classifiers are trained with noisy samples.
For fairness, we augmented the dataset of the baseline algorithm in a similar way as for the network; we created samples by adding new random realizations of the noise.
We stop adding new samples in the classifier once the validation error converges.
This process is detailed in \ref{sec:dataset_augmentation}.
We tune the SVM regularization parameter by cross-validating with the validation set.

\subsection{Selected architecture}
\label{sec:selected_architecture}

The choice of a particular HealpixNet architecture highly depends on the problem at hand. Convolution layers construct \emph{almost} rotational equivariant features and the statistical layer can turn them into rotational invariant ones. In our case, we are trying to discriminate samples of two cosmological maps. Hence, we assume that each pixel carries some information about the distribution. Our principal architecture is a fully convolutional network referred as the FCN variant of HealpixNet. Thanks to 6 graph convolution layers (GC sizes: 16, 32, 64, 64, 64, 2) we first build the statistical evidence of each distribution for each pixel of a down-sampled sphere. The last graph convolution layer is composed of 2 channels as we have 2 distributions. Then we use a statistical 'mean' layer (SL) to average the evidence for each distribution and we compute the probabilities thanks to a softmax layer (SM). We use batch normalization (BN), pooling (P) and relu non-linearity $\sigma$ for each convolutional layer. The order of the convolution kernel was set to $K=5$. The network can be summarized as
\begin{equation}
FCN = SM \circ ST_{\text{mean}} \circ L_6 \circ L_5 \circ L_4 \circ L_3 \circ L_2 \circ L_1
\end{equation}
\begin{center}
where \hspace{0.5cm} \begin{tabular}{lll}
   $L_1$ &  $=$ &$ P  \circ \sigma \circ BN  \circ GC_{16}$ \\
   $L_2$ &  $=$ &$ P  \circ \sigma \circ BN  \circ GC_{32}$ \\
   $L_3,L_4,L_5$ & $=$ &$ P \circ  \sigma \circ BN  \circ GC_{64}$ \\
   $L_6$ &  $=$& $ \sigma \circ BN  \circ GC_{2}$ \\
\end{tabular}
\end{center}
Thanks to its statistical layer, the FCN architecture is close invariant to rotation.
We also tried a more traditional architecture, where the statistical and last convolutional layers are replaced by a fully connected layer. Hence we end up with a convolutional neural network (CNN) that is not invariant to rotation anymore. The network is referred as CNN variant of HealpixNet and can be summarized as
\begin{equation}
CNN = SM \circ \sigma \circ FC_2 \circ L_5 \circ L_4 \circ L_3 \circ L_2 \circ L_1.
\end{equation}
We use the ADAM optimizer, \cite{kingma2014adam}, with $\beta_1=0.9$, $\beta_2=0.999$ and an initial learning rate of $2e-4$ that is exponentially decreased by $0.999$ at each step.
All models were trained $80$ epochs with a batch size of $16\times o^2$. With this choice, all models receive an identical amount of data within a batch and were trained with $1920$ gradient steps.
Training took less than $5$ hours for each model using a single NVIDIA Tesla K20.
% The CPU is probably slow which explain the 5 hours. I believe we could be much faster than that by computer less summaries and improving the data. But, Michael, is OKAY to have to margin of improvement :-)

\subsection{Results}

\begin{figure*}
\centering
\includegraphics[width=0.32\linewidth]{result_order1}
\hfill
\includegraphics[width=0.32\linewidth]{result_order2}
\hfill
\includegraphics[width=0.32\linewidth]{result_order4}
\caption{
Classification errors for the 3 different areas of the sphere.
Green lines show the performance of the two HealpixNet architectures, blue of the PDF+SVM, and red of the histogram+SVM.
% Green dashed line corresponds to the performance of CNN without the statistical layer.
The noise level was increased from zero to $2\times$ the standard deviation of the mass map.
}
\label{fig:results}
\end{figure*}

\figref{results} presents the results for $5$ different noise levels and $3$ different sample areas.
HealpixNet (FCN and CNN) has a significant lead for all levels of noise and sample areas.
In particular, the difference seems to increase as the problem becomes more complex; as the order is increased, there is less information in each sample.
This is likely due to the fact that the HealpixNet can learn optimal features for the problem and does not rely on hand-designed features.

We observe that the PSD is unable to perform the desired task.
The main reason is that the two different models were designed to have very similar PSDs (see \figref{psd_sigma3}).
As a result, one needs to use other statistics to solve the problem.
In this case, the histogram features allow for a significant improvement over the PSD ones.
Unfortunately, while the histogram features contain information about the distribution of pixels, they do not include any spatial information.
In contrast, both the PSD features and the HealpixNet can exploit the spatial information.

% Note that without this graph structure, a fully connected neural network approach would have to be used.
% Problematically, fully connected neural networks generally scales squarely with their number of inputs.
% \TK{I don't understand this comment.} \nati{Maybe we should leave it out then. It is not that important.}

\nati{Michael: I am highly uncertain of what should be kept in the following paragraph. Maybe the full paragraph should be left out!}
While testing the FCN and CNN architectures, we made the following empirical observations.
First, Chebyshev polynomial seems more stable than monomials ($\theta_k$ in \eqnref{graph_convolution_monomial}), in the sense that the training loss had a more monotone decrease.
Nevertheless once the network is trained, we could not observe a significant accuracy difference.
Second, using a statistical layer (FCN) to get equivariant features slightly improved the accuracy in our problem.
We tried $4$ different layers `mean', `variance', `mean + variance' and `histogram'.
The `mean', `histogram' and `mean + variance' were providing the same level of accuracy, with pure `variance' being slightly worse. Hence we chose to simply use the `mean' statistic.
Third, adding fully connected layers after the statistical layer does not improve the performance, but lead to models requiring more training steps and regularization.
Fourth, using $\ell_2$ regularization does not help either with the performance or the training of the models.
Fifth, we recommend initializing the Chebyshev coefficients with a centered Gaussian distribution with standard deviation $\sqrt{2/(F * (K + 0.5))}$, where $K$ is the Chebyshev order and $F$ the number of input channels. This standard deviation has the property to keep the energy of the signal more or less at the same level between the different layers.
% Nati to Michael: The problem with the previous claim is that it depends on the non-linarity. Furthermore, does it make sense to make such a claim if we use batch norm?
Eventually, we observe that rescaling the Laplacian eigenvalues between $[-a,a]$, where $1<a\leq1$ significantly helps to stabilize the optimization. For our experiment we use $a=0.75$.





\subsection{Filter visualization}
One common visualization for CNN is to observe the shape of the learned filters.
Since our construction leads to almost (up to the sampling irregularities) spherical filters, we plot in \figref{learned_filter} both the radial profile and a gnomonic projection on a plane of a random selection of learned filters.
The filters are selected from the last layer of the network corresponding the experiment with order $o=2$ for a relative noise level of $2$.
Nevertheless, all networks presented visually similar gnomonic and profile patterns.
% The gnomonic projection clearly exibits the sampling issue of HEALPix.
% \TK{what issue? Commenting out for now}
Details of how the convolution kernels are plotted are described in \ref{sec:filter_visualization}.
While it is usually difficult to interpret the shape of the filters in the context of the type of data, we can notice that they often have a ``peak'' like structures.
An example of filter interpretation was demonstrated in \citep{Ribli2018learningfrom}.
% \todo{Tomek: can you say something about the filters.}
% \TK{Done}
% Nati: Note that filer are almost not evolving during the training process. It is not surprising as our architecture is likely to be overparametrized. If we want to have interpretable filters, we probably have to use a much smaller architecture.

\begin{figure*}
\centering
\includegraphics[width=0.47\linewidth]{section_filter_last}
\hfill
\includegraphics[width=0.45\linewidth]{gnonomic_filter_last}
\caption{24 learned filters selected from the fifth spherical convolutional layer $L_5$. Left: section. Right: gnonomic view.}
\label{fig:learned_filter}
\end{figure*}

% \section{Discussion}

% Because of the spherical domain, the method presented here restricts the shape of the filters learned by the network to be radial.
% While this may be a less general design compared to the one used by conventional CNNs on flat images, we found it to still work efficiently for our test cases.
% The layered structure of the network can partially compensate for that.
% Further generalizations to non-radial filters may be possible [cite?]\TK{update here}, but we leave it to future work.

% \nati{Should the discussion be merged with the result section?}
% \TK{I think yes!}

\section{Conclusion}
\label{sec:conclusion}

In this contribution we presented HealpixNet: a spherical convolutional neural network for the HEALPix sampling.
The core of our method is the use of a graph to represent the pixel grid on the sphere.
This allows us to leverage the advantages of the graph convolution; it is both efficient, with a complexity of $\mathcal{O}(N_{pix})$, and flexible, which allows to work only on a part of the sphere.
Spherical properties of the domain are still captured well.
The method presented here restricts the shape of the filters learned by the network to be radial.
While this may be a less general design compared to the one used by conventional CNNs on flat images, we found it to still work efficiently for our test cases.
The layered structure of the network can partially compensate for that.
% Further generalizations to non-radial filters may be possible [cite?]\TK{update here}, but we leave it to future work.

We demonstrate that the neural network systematically and significantly outperforms our benchmark methods on an example problem of cosmological model discrimination with weak lensing mass maps, designed similarly to \citep{schmelze2017cosmologicalmodel}.
The maps were produced from two cosmological models with varying $\sigma_8$ and $\Omega_m$, chosen to follow the typical weak lensing degeneracy in these parameters, so that the power spectra for these models are very similar.
We compared the performance of the HealpixNet CNN versus that of two SVM-based classifiers: one trained on the spherical harmonics power spectrum, and the other on the pixel density histogram.
Notably, HEALPix maintains good classification accuracy even for high noise levels and part-sky areas.

We show that the modeling the discretised sphere by a graph enables an efficient convolution operation on HEALPix sampling.
Graph-based representation of the sphere can display small imprecisions in rotation invariance, the result of which is that an action of a graph filter slightly depends on the location.
For applications that can tolerate this property, a graph-based representation may be a worthwhile alternative.
For example, a machine learning based cosmological inference algorithm can in principle tolerate this property, as it requires the simulations to be represented the same way as observations anyway.
This way, imperfections in representation will affect the simulations and real data in the same way, and will not cause biases in the analysis result.

The main product of this contribution is HealpixNet: a small and easy-to-use python package for spherical analysis of cosmological data.
The code and data used in this work are publicly available\footnote{\url{https://github.com/SwissDataScienceCenter/HealpixNet}}.
The code was designed in a way to enable straightforward modifications of the architectures, so that HealpixNet can easily be used for a number of typical machine learning tasks, such as classification, regression, or segmentation.
Notably, for a problem of cosmological parameter estimation \citep{fluri2018deep,gupta2018nongaussianinformation}, it is easy to replace the classification loss task with a regression loss.
It should also be possible use dense layer for an output and perform segmentation tasks, such as masking, flagging, or object detection.

As a future work, it would be interesting to further investigate the link between the graph Fourier basis and the spherical harmonics. Furthermore, the influence of the irregular sampling on the rotational equivariance should be quantified empirically and ideally bounded theoretically.
Further comparison of HealpixNet to other spherical CNN algorithms, with different sampling schemes, would also be worthwhile.

% Hence, it relaxes the iso-latitude constraint on sampling schemes who aim to enable fast convolutions.
% \TK{I would move the info about possible relaxation of the iso-latitude thing to a separate paragraph at the end on conclusions - future prospects?}
% this relaxation might enable researchers to consider sampling sets with different properties.
% \TK{this I don't understand}

\section*{Acknowledgements}

This work was supported by a grant from the Swiss Data Science Centre (SDCS) under project ID \textit{sd01 - DLOC:  Deep Learning for Observational Cosmology} and grant number 200021\_169130 from the Swiss National Science Foundation.
\nati{@Tomek: do we need to thank Janis?}
We would like to thank Jean-François Cardoso for helpful discussions about the spherical harmonics.

\appendix

\section{Graph Fourier modes and spherical harmonics}
\label{sec:comparison_spherical_harmonics}
The first 16 eigenvectors $[\b u_1, \ldots, \b u_{16}]$ of the graph Laplacian $\L$, forming the lower part of the graph Fourier basis $\U$, are shown in \figref{graph_harmonics}.
Let us further observe the spectral properties of our constructed spherical graph laplacian $\L$.
Its eigenvalues, shown in \figref{graph_eigenvalues}, are clearly organized in frequency groups of $2\ell + 1$ orders for each degree $\ell$.
We remind the reader that the amplitude of the Laplacian eigenvalue is proportional to the sum of the variations of its associated eigenvector. Furthermore, all spherical harmonics with the same order $\ell$ have the same variation. Hence, the fact that the Laplacian eigenvalues are grouped in blocks of size $2\ell + 1$ is a hint that the graph eigenvectors approximate the spherical harmonics.
In order to push the comparison one step further, we show the correspondence (scalar product) between the subspaces spanned by the graph Fourier modes and the spherical harmonics in \figref{subspace_harmonics_eigenvectors}.
The block-diagonal structure of the matrix, as opposed to diagonal, results the fact that the phase of the graph eigenvector is not aligned with the one of the spherical harmonics.

While these indications show that the constructed graph Fourier basis approximates well the spherical harmonics, one should not forget that the small irregularities in the sampling (non-constant number of neighboring pixels and varying distance between pixels, see \figref{healpix_graph_4}) have an important effect on the graph Fourier modes.
First, we believe that they are responsible for energy leaking outside of the block diagonal in \figref{subspace_harmonics_eigenvectors}.
Second, as the resolution is increased with $N_{side} \rightarrow \infty$ and $N_{pix} \rightarrow \infty$, we are still unsure if the eigenvectors would converge towards the spherical harmonics. We believe that it might be the case for a different construction of the graph (fully connected) and that a proof could be built on top of the work of~\cite{belkin2007convergence}. That is, however, out of the scope of this contribution.
Third, counter-intuitively, some eigenvectors will be localized~\citep{perraudin2018global}, i.e, they will span a small part of the sphere.
Nevertheless, our experiments suggest that these downsides do not have an important effect on the convolution nor hinder the performance of the neural network.

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{graph_eigenvalues}
	\caption{The eigenvalues $\bLambda$ of the graph Laplacian $\L = \U \bLambda \U\trans$, which corresponds to squared frequencies, are clearly organized in groups. Each group corresponds to a degree $\ell$ of the spherical harmonics. Each degree has $2\ell + 1$ orders. See also \figref{graph_harmonics}.}
	\label{fig:graph_eigenvalues}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{subspace_harmonics_eigenvectors}
	\caption{Correspondence between the subspaces spanned by the graph Fourier modes and the spherical harmonics. Each pixel on the plot is the dot product between one spherical harmonic and one graph Fourier mode $\b u_i$. The plot clearly shows how the subspaces are aligned: modes and harmonics which correspond to different degrees $\ell$ are mostly orthogonal to each other, while modes and harmonics which correspond to the same degree $\ell$ are linearly dependent. There are $2 \ell + 1$ orders per degree $\ell$. Moreover, we see that the Fourier modes have the correct symmetries, indicated by the perfect orthogonality between even and odd functions.}
	\label{fig:subspace_harmonics_eigenvectors}
\end{figure}

\section{Border effects}
\label{sec:border_effects}

One should not forget that a significant part of our analysis is done with a full sphere and that in practice we often use only part of the graph as the data may be incomplete (see \figref{example_maps}).
In this case, the graph setting used through this contribution correspond to assume reflective border conditions.
It is irrelevant when working on the complete sphere as this surface has no border. Nevertheless, dealing working with a subpart of the sphere, its border slightly affects the convolution.
As depicted in \figref{border_effects}, a filter localized near the border of a part of the sphere (via $h(\L) \b \delta_i$) no longer has an isotropic profile.
These border effects can, however, be mitigated by padding with zeros a small area around the part of interest.

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{border_effects}
	\caption{Convolution kernel (also called filter) $h$ localized in the center and left corner of a surface. A filter is localized on a pixel $i$ as $\T_i h = h(\L) \b \delta_i$ (see \secref{graph_convolution} and \eqnref{graph_convolution_spatial}). The graph is built from $1/12^\text{th}$ of the sphere at $N_{side} = 16$. The filter is not isotropic anymore when localized on the left corner due to border effects. The graph representation of a manifold assumes reflective border conditions.}
	\label{fig:border_effects}
\end{figure}

\section{Example: heat diffusion}
\label{sec:heat_diffusion}
\label{sec:filter_visualization}

Let us consider the heat diffusion problem
\begin{equation}
  \L \b{f}(t) = \tau \partial_t \b{f}(t),
  \label{eqn:heat_equation}
\end{equation}
where $\b{f}: \R_+ \rightarrow \R^{N_{pix}}$. Given the initial condition
$\b{f}(0)$, the solution of~\eqnref{heat_equation} can be expressed as
\begin{equation*}
  \b{f}(t) = e^{-\L \tau t} \b{f}(0) = \U e^{-\bLambda t \tau} \U\trans \g{f}(0) = K_t(\L) \b{f}(0),
\end{equation*}
which is, by definition, the convolution of the signal $\b{f}(0)$ with the kernel $K_t(\lambda)=e^{-\tau t \lambda}$. Since the kernel $K_t$ is applied to the graph eigenvalues $\bLambda$, which can be interpreted as squared frequencies, it can also be considered as a generalization of the Gaussian kernel on the sphere. \figref{gaussian_filters_comparizon} shows the effect of the convolution by diffusing a unit of heat for $\tau=1$ at various times $t$. By comparing the graph convolution with the spherical symmetric Gaussian smoothing, we observe that both techniques lead to similar results (see \figref{gaussian_filters_comparizon}). While the graph convolution remains different from the spherical convolution, this small experiment shows that, providing the correct parameters, the graph convolution can approximate the spherical convolution. For additional insights about the graph kernel $K_t$, we refer to the \figref{gaussian_filters_visualization}.
% and~\ref{sec:filter_visualization}.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{gaussian_filters_sphere}
  \caption{Comparison of convolution with the graph and the spherical harmonics ($N_{side} = 16$).
  Top: Diffusion of a unit of heat for different times $t$ using the graph.
  Bottom: spherical symmetric Gaussian smoothing for different $\sigma$ (arcmin).
  Relative difference between graph convolution and spherical smoothing: $10.4$\%, $4.8$\%, $3.8$\%.
% nati: I commented this issue as this is already in appendix and it will go a bit too far. We will not do an appendix of appendix :-).
% \todo{The main issue with our filters is that their shape depends on the localization. It would be nice to measure the expectation and variance of the error over all locations. That would show how severe the distortion is.}
% \nati{Let us keep that for the next paper. I am quite sure, it is negligible in this particular case.}
}
  \label{fig:gaussian_filters_comparizon}
\end{figure}

Furthermore, this result is another sign that the constructed graph is able to capture the spherical
structure of the HEALPix sampling. In some applications, where the
exactitude of the convolution is not a requirement, such as de-noising, graph convolution could be used instead of using the spherical harmonics.
The fact that the graph convolution is not exactly rotational equivariant is probably compensated by the fact that in a neural network setting the convolution kernels are learned.
\todo{not ideal tho as the graph convolution depends on the localization}

% \section{Filter visualization}
% \label{sec:filter_visualization}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{gaussian_filters_spectral}
\caption{Visualization of the convolution kernel $K_t(x)=e^{-\tau t x}$ in spectral domain.}
\vspace{0.3in}
\includegraphics[width=\linewidth]{gaussian_filters_gnomonic}
\caption{Visualization of the convolution kernel $K_t(x)=e^{-\tau t x}$: cross-section of the kernel through the pixels along the equator.}
\vspace{0.3in}
\includegraphics[width=\linewidth]{gaussian_filters_section}
\caption{Visualization of the convolution kernel $K_t(x)=e^{-\tau t x}$ in a gnomonic projection.}
\label{fig:gaussian_filters_visualization}
\end{figure}

In \figref{gaussian_filters_visualization}, we further leverage this example to present the three visualizations of a HEALPix graph convolution kernel.
We remember that the convolution kernel resulting from the heat diffusion is defined as $K_t(x)=e^{-\tau t x}$. For our visualization, we simply plot this function, i.e., we evaluate $K_t$
at the graph eigenvalues $\text{diag}(\bLambda)$. Note that, the lower eigenvalues $\lambda$ correspond to the lower frequencies, i.e., the spectral mode with less variation.
As a second visualization, we observe the kernel directly on the sphere. As the kernel $K_t$ is defined in the graph spectral domain, we convolve a Kroneker to obtain a representation on the sphere. We then plot the result with a gnomonic projection.
For our third visualization, we leverage the fact that we are working on the sphere and hence theoretically have  spherical filters (up to the irregularities of the sampling). We plot the section of the convoluted Kroneker.
% To do so, we convolve a Kroneker on the equator and use the equator for our section as shown in~\figref{index_section}.
To do so, we convolve a Kroneker on the nodes along the equator and use the equator for our section.
Note that, because of the small irregularities in the HEALPix sampling, the second and the third methods are subject to small variations depending on the chosen position of the Kroneker.




% \begin{figure}
% \centering
% \includegraphics[width=0.6\linewidth]{index_plotting_order20_nside16}
% \caption{Indexes selected for the section ploting of \figref{gaussian_filters_visualization} middle. The delta was placed on the yellow node.}
% \label{fig:index_section}
% \end{figure}

\section{Augmentation of the dataset for the SVM classifier}
\label{sec:dataset_augmentation} The original number of samples $480$, $1920$,
$7680$ respectively for order $o=1,2,4$ is considered small to train a deep architecture,
especially when one desire to build a noise robust
classifier. As a result, we use a classical dataset augmentation technique.
Before entering the network for training each sample is added a random
realization of Gaussian noise. The effect is twofold. First, the network never
ends up seeing the same sample and is less likely to over-fit the training set.
Second the trained network will be robust to Gaussian noise.

When comparing the network to the baselines, we want to ensure that the SVM classifier has
access to the same amount of data as the network, i.e, potentially an
infinite number of samples. Hence, we fit different linear SVM classifiers using
various training set size until we experimentally observe that
increasing the amount of data does not improve the accuracy. The validation
set remain the same and is used for cross-validation to tune the L2
penalization parameter of SVM. Eventually, we evaluate the final classifier on
the testing set. An example of the evolution of the training and valdication
error is shown in \figref{hist_error_evolution}.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{hist_error_order2_noise1_5}
\caption{Evolution curve of the error with respect to the number of training samples for histogram features and a linear classifier (setting: order 2, relative noise level: 1.5). The validation error might be slightly below the training error because we use it for cross-validation.}
\label{fig:hist_error_evolution}
\end{figure}

%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%
\section*{Bibliography}
\bibliographystyle{elsarticle-harv}
\bibliography{biblio}

\end{document}

\endinput
%%
%% End of file `elsarticle-template-harv.tex'.
